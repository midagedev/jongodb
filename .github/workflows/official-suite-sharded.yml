name: Official Suite Sharded

on:
  workflow_dispatch:
    inputs:
      official_specs_ref:
        description: "Commit/tag/branch in mongodb/specifications"
        required: false
        default: "99704fa8860777da1d919ef765af1e41e75f5859"
      utf_gate_mode:
        description: "UTF mismatch/error gate mode: off | warn | strict"
        required: false
        default: "warn"
  pull_request:
    branches:
      - main
    paths:
      - "src/main/**"
      - "src/test/**"
      - "testkit/**"
      - "scripts/ci/**"
      - ".github/workflows/official-suite-sharded.yml"
      - "build.gradle.kts"
  schedule:
    - cron: "0 4 * * *"

permissions:
  contents: read
  actions: read

concurrency:
  group: official-suite-sharded-${{ github.ref }}
  cancel-in-progress: true

jobs:
  utf-shards:
    name: UTF shard ${{ matrix.shard_index }}
    runs-on: ubuntu-latest
    timeout-minutes: 50
    strategy:
      fail-fast: false
      matrix:
        shard_index: [0, 1, 2]
    env:
      OFFICIAL_SPECS_REPO: https://github.com/mongodb/specifications.git
      OFFICIAL_SPECS_REF: ${{ github.event.inputs.official_specs_ref || '99704fa8860777da1d919ef765af1e41e75f5859' }}
      SHARD_COUNT: "3"
      UTF_SEED: "r3-official-suite-v1"
      UTF_REPLAY_LIMIT: "30"
      MONGO_CONTAINER_NAME: jongodb-replset
      MONGO_REPLSET_NAME: rs0
      MONGO_PORT: "27017"
      REPLSET_WAIT_TIMEOUT_SECONDS: "120"
      REPLSET_WAIT_INTERVAL_SECONDS: "2"
      REPLSET_DIAGNOSTICS_DIR: build/reports/replset-diagnostics/shard-${{ matrix.shard_index }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Temurin 17
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "17"

      - name: Set up Gradle
        uses: gradle/actions/setup-gradle@v4
        with:
          gradle-version: "8.11.1"

      - name: Make scripts executable
        run: chmod +x scripts/ci/*.sh

      - name: Bootstrap replica set fixture
        run: ./scripts/ci/bootstrap-replset.sh

      - name: Prepare official spec checkout
        id: spec_checkout
        run: |
          ./scripts/ci/prepare-official-specs.sh \
            --repo "${OFFICIAL_SPECS_REPO}" \
            --ref "${OFFICIAL_SPECS_REF}" \
            --dest "${RUNNER_TEMP}/mongodb-specifications"

      - name: Run baseline shard
        run: |
          ./scripts/ci/run-utf-shard.sh \
            --spec-repo-root "${RUNNER_TEMP}/mongodb-specifications" \
            --shard-index "${{ matrix.shard_index }}" \
            --shard-count "${SHARD_COUNT}" \
            --output-dir "build/reports/unified-spec-shards/shard-${{ matrix.shard_index }}/baseline" \
            --seed "${UTF_SEED}" \
            --replay-limit "${UTF_REPLAY_LIMIT}" \
            --mongo-uri "${JONGODB_REAL_MONGOD_URI}" \
            --gradle-cmd gradle

      - name: Run rerun shard (flake gate input)
        run: |
          ./scripts/ci/run-utf-shard.sh \
            --spec-repo-root "${RUNNER_TEMP}/mongodb-specifications" \
            --shard-index "${{ matrix.shard_index }}" \
            --shard-count "${SHARD_COUNT}" \
            --output-dir "build/reports/unified-spec-shards/shard-${{ matrix.shard_index }}/rerun" \
            --seed "${UTF_SEED}" \
            --replay-limit "${UTF_REPLAY_LIMIT}" \
            --mongo-uri "${JONGODB_REAL_MONGOD_URI}" \
            --gradle-cmd gradle

      - name: Enforce flake gate (baseline vs rerun consistency)
        run: |
          ./scripts/ci/assert-utf-shard-consistency.sh \
            --baseline-json "build/reports/unified-spec-shards/shard-${{ matrix.shard_index }}/baseline/utf-differential-report.json" \
            --rerun-json "build/reports/unified-spec-shards/shard-${{ matrix.shard_index }}/rerun/utf-differential-report.json"

      - name: Collect replica set diagnostics
        if: always()
        run: ./scripts/ci/collect-replset-diagnostics.sh "${REPLSET_DIAGNOSTICS_DIR}"

      - name: Upload shard artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: utf-shard-${{ matrix.shard_index }}
          path: |
            build/reports/unified-spec-shards/shard-${{ matrix.shard_index }}/**/*.json
            build/reports/unified-spec-shards/shard-${{ matrix.shard_index }}/**/*.md
            build/reports/unified-spec-shards/shard-${{ matrix.shard_index }}/**/*.txt
            build/reports/replset-diagnostics/shard-${{ matrix.shard_index }}/**
          if-no-files-found: error
          retention-days: 14

      - name: Teardown replica set fixture
        if: always()
        run: ./scripts/ci/teardown-replset.sh

  shard-summary:
    name: Shard summary
    runs-on: ubuntu-latest
    needs: [utf-shards]
    if: always()
    env:
      UTF_GATE_MODE: ${{ github.event_name == 'schedule' && 'strict' || github.event.inputs.utf_gate_mode || 'warn' }}
    steps:
      - name: Download shard 0 artifact
        uses: actions/download-artifact@v4
        with:
          name: utf-shard-0
          path: artifacts/utf-shard-0

      - name: Download shard 1 artifact
        uses: actions/download-artifact@v4
        with:
          name: utf-shard-1
          path: artifacts/utf-shard-1

      - name: Download shard 2 artifact
        uses: actions/download-artifact@v4
        with:
          name: utf-shard-2
          path: artifacts/utf-shard-2

      - name: Build shard summary markdown and evaluate UTF gate
        run: |
          python3 - <<'PY'
          import json
          import os
          from pathlib import Path

          shard_roots = [Path("artifacts/utf-shard-0"), Path("artifacts/utf-shard-1"), Path("artifacts/utf-shard-2")]
          out = Path("artifacts/utf-shard-summary.md")
          gate_mode = os.environ.get("UTF_GATE_MODE", "warn").strip().lower()
          if gate_mode not in {"off", "warn", "strict"}:
            raise SystemExit(f"invalid UTF gate mode: {gate_mode} (expected off|warn|strict)")

          lines = ["# UTF shard summary", ""]
          baseline_totals = {"total": 0, "match": 0, "mismatch": 0, "error": 0}
          rerun_totals = {"total": 0, "match": 0, "mismatch": 0, "error": 0}
          for shard_index, root in enumerate(shard_roots):
            baseline_json = next(root.glob("**/baseline/utf-differential-report.json"), None)
            rerun_json = next(root.glob("**/rerun/utf-differential-report.json"), None)
            if baseline_json is None or rerun_json is None:
              raise SystemExit(f"missing baseline/rerun report for shard {shard_index}")

            baseline = json.loads(baseline_json.read_text(encoding="utf-8"))
            rerun = json.loads(rerun_json.read_text(encoding="utf-8"))
            b = baseline["differentialSummary"]
            r = rerun["differentialSummary"]
            for key in baseline_totals:
              baseline_totals[key] += int(b.get(key, 0))
              rerun_totals[key] += int(r.get(key, 0))

            baseline_pass = (int(b.get("match", 0)) / int(b.get("total", 0)) * 100.0) if int(b.get("total", 0)) else 100.0
            rerun_pass = (int(r.get("match", 0)) / int(r.get("total", 0)) * 100.0) if int(r.get("total", 0)) else 100.0
            lines.append(f"## shard-{shard_index}")
            lines.append(f"- baseline: total={b['total']} match={b['match']} mismatch={b['mismatch']} error={b['error']} passRate={baseline_pass:.2f}%")
            lines.append(f"- rerun: total={r['total']} match={r['match']} mismatch={r['mismatch']} error={r['error']} passRate={rerun_pass:.2f}%")
            lines.append("")

          baseline_pass = (baseline_totals["match"] / baseline_totals["total"] * 100.0) if baseline_totals["total"] else 100.0
          rerun_pass = (rerun_totals["match"] / rerun_totals["total"] * 100.0) if rerun_totals["total"] else 100.0
          lines.append("## aggregate")
          lines.append(f"- baseline: total={baseline_totals['total']} match={baseline_totals['match']} mismatch={baseline_totals['mismatch']} error={baseline_totals['error']} passRate={baseline_pass:.2f}%")
          lines.append(f"- rerun: total={rerun_totals['total']} match={rerun_totals['match']} mismatch={rerun_totals['mismatch']} error={rerun_totals['error']} passRate={rerun_pass:.2f}%")
          lines.append(f"- gateMode: {gate_mode}")
          lines.append("")

          gate_triggered = (
            baseline_totals["mismatch"] > 0
            or baseline_totals["error"] > 0
            or rerun_totals["mismatch"] > 0
            or rerun_totals["error"] > 0
          )
          if gate_triggered:
            gate_message = (
              "UTF mismatch/error gate triggered: "
              f"baseline(mismatch={baseline_totals['mismatch']}, error={baseline_totals['error']}), "
              f"rerun(mismatch={rerun_totals['mismatch']}, error={rerun_totals['error']})"
            )
            lines.append(f"- gateResult: FAIL ({gate_message})")
            if gate_mode == "warn":
              print(f"::warning::{gate_message}")
            elif gate_mode == "strict":
              print(f"::error::{gate_message}")
          else:
            lines.append("- gateResult: PASS")

          out.write_text("\n".join(lines), encoding="utf-8")
          print(out.read_text(encoding="utf-8"))

          step_summary = os.environ.get("GITHUB_STEP_SUMMARY")
          if step_summary:
            with Path(step_summary).open("a", encoding="utf-8") as handle:
              handle.write("\n")
              handle.write(out.read_text(encoding="utf-8"))
              handle.write("\n")

          if gate_triggered and gate_mode == "strict":
            raise SystemExit("UTF mismatch/error strict gate failed")
          PY

      - name: Build zero-mismatch streak snapshot
        env:
          GH_TOKEN: ${{ github.token }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          python3 - <<'PY'
          import io
          import json
          import os
          import re
          import urllib.request
          import zipfile
          from datetime import datetime, timezone
          from pathlib import Path

          WINDOW_SIZE = 10
          summary_path = Path("artifacts/utf-shard-summary.md")
          output_json = Path("artifacts/utf-shard-streak.json")
          output_md = Path("artifacts/utf-shard-streak.md")
          repo = os.environ["GITHUB_REPOSITORY"]
          token = os.environ.get("GH_TOKEN", "")
          run_id = int(os.environ.get("GITHUB_RUN_ID", "0"))
          run_url = f"{os.environ.get('GITHUB_SERVER_URL', 'https://github.com')}/{repo}/actions/runs/{run_id}"
          step_summary = os.environ.get("GITHUB_STEP_SUMMARY")

          aggregate_pattern = re.compile(
              r"## aggregate\s+"
              r"- baseline: total=(?P<b_total>\d+) match=(?P<b_match>\d+) mismatch=(?P<b_mismatch>\d+) error=(?P<b_error>\d+).*?\n"
              r"- rerun: total=(?P<r_total>\d+) match=(?P<r_match>\d+) mismatch=(?P<r_mismatch>\d+) error=(?P<r_error>\d+)",
              re.S,
          )

          def parse_aggregate_metrics(text: str):
              match = aggregate_pattern.search(text)
              if not match:
                  return None
              metrics = {
                  "baseline": {
                      "total": int(match.group("b_total")),
                      "match": int(match.group("b_match")),
                      "mismatch": int(match.group("b_mismatch")),
                      "error": int(match.group("b_error")),
                  },
                  "rerun": {
                      "total": int(match.group("r_total")),
                      "match": int(match.group("r_match")),
                      "mismatch": int(match.group("r_mismatch")),
                      "error": int(match.group("r_error")),
                  },
              }
              metrics["zeroMismatchError"] = (
                  metrics["baseline"]["mismatch"] == 0
                  and metrics["baseline"]["error"] == 0
                  and metrics["rerun"]["mismatch"] == 0
                  and metrics["rerun"]["error"] == 0
              )
              return metrics

          def request_json(url: str):
              req = urllib.request.Request(
                  url,
                  headers={
                      "Authorization": f"Bearer {token}",
                      "Accept": "application/vnd.github+json",
                      "User-Agent": "jongodb-utf-streak",
                  },
              )
              with urllib.request.urlopen(req, timeout=30) as res:
                  return json.loads(res.read().decode("utf-8"))

          def request_bytes(url: str) -> bytes:
              req = urllib.request.Request(
                  url,
                  headers={
                      "Authorization": f"Bearer {token}",
                      "Accept": "application/vnd.github+json",
                      "User-Agent": "jongodb-utf-streak",
                  },
              )
              with urllib.request.urlopen(req, timeout=60) as res:
                  return res.read()

          def read_utf_summary_from_run(target_run_id: int):
              artifacts = request_json(
                  f"https://api.github.com/repos/{repo}/actions/runs/{target_run_id}/artifacts?per_page=100"
              )
              for artifact in artifacts.get("artifacts", []):
                  if artifact.get("expired"):
                      continue
                  if artifact.get("name") != "utf-shard-summary":
                      continue
                  archive = zipfile.ZipFile(io.BytesIO(request_bytes(artifact["archive_download_url"])))
                  for member in archive.namelist():
                      if member.endswith("utf-shard-summary.md"):
                          return archive.read(member).decode("utf-8")
              return None

          if not summary_path.exists():
              raise SystemExit(f"missing current summary: {summary_path}")
          current_metrics = parse_aggregate_metrics(summary_path.read_text(encoding="utf-8"))
          if current_metrics is None:
              raise SystemExit("failed to parse aggregate metrics from current utf summary")

          history = [
              {
                  "runId": run_id,
                  "event": os.environ.get("GITHUB_EVENT_NAME"),
                  "conclusion": "in_progress",
                  "url": run_url,
                  "createdAt": datetime.now(timezone.utc).isoformat(),
                  "metrics": current_metrics,
                  "zeroMismatchError": current_metrics["zeroMismatchError"],
                  "source": "current-run-artifact",
              }
          ]

          runs = request_json(
              f"https://api.github.com/repos/{repo}/actions/workflows/official-suite-sharded.yml/runs"
              "?branch=main&event=schedule&status=completed&per_page=30"
          ).get("workflow_runs", [])

          for run in runs:
              target_run_id = int(run.get("id", 0))
              if target_run_id == run_id:
                  continue
              if len(history) >= WINDOW_SIZE:
                  break

              entry = {
                  "runId": target_run_id,
                  "event": run.get("event"),
                  "conclusion": run.get("conclusion"),
                  "url": run.get("html_url"),
                  "createdAt": run.get("created_at"),
                  "metrics": None,
                  "zeroMismatchError": False,
                  "source": "schedule-history",
              }
              try:
                  text = read_utf_summary_from_run(target_run_id)
                  if text is not None:
                      parsed = parse_aggregate_metrics(text)
                      if parsed is not None:
                          entry["metrics"] = parsed
                          entry["zeroMismatchError"] = parsed["zeroMismatchError"]
                      else:
                          entry["note"] = "summary-parse-failed"
                  else:
                      entry["note"] = "utf-shard-summary-artifact-missing"
              except Exception as exc:
                  entry["note"] = f"artifact-read-error: {exc}"
              history.append(entry)

          streak = 0
          for entry in history:
              if entry.get("zeroMismatchError"):
                  streak += 1
                  continue
              break

          result = {
              "generatedAt": datetime.now(timezone.utc).isoformat(),
              "windowSize": WINDOW_SIZE,
              "workflow": "official-suite-sharded",
              "officialZeroMismatchStreak": streak,
              "history": history,
          }
          output_json.write_text(json.dumps(result, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")

          lines = [
              "# UTF Zero-Mismatch Streak",
              "",
              f"- generatedAt: {result['generatedAt']}",
              f"- officialZeroMismatchStreak: {streak}",
              f"- windowSize: {WINDOW_SIZE}",
              "",
              "## recentRuns",
          ]
          for entry in history:
              metrics = entry.get("metrics") or {}
              baseline = metrics.get("baseline", {})
              rerun = metrics.get("rerun", {})
              lines.append(
                  f"- runId={entry.get('runId')} event={entry.get('event')} conclusion={entry.get('conclusion')} "
                  f"zeroMismatchError={entry.get('zeroMismatchError')} "
                  f"baseline(mismatch={baseline.get('mismatch', 'n/a')},error={baseline.get('error', 'n/a')}) "
                  f"rerun(mismatch={rerun.get('mismatch', 'n/a')},error={rerun.get('error', 'n/a')})"
              )
          output_md.write_text("\n".join(lines) + "\n", encoding="utf-8")
          print(output_md.read_text(encoding="utf-8"))

          if step_summary:
              with Path(step_summary).open("a", encoding="utf-8") as handle:
                  handle.write("\n")
                  handle.write(output_md.read_text(encoding="utf-8"))
          PY

      - name: Upload summary artifact
        uses: actions/upload-artifact@v4
        with:
          name: utf-shard-summary
          path: |
            artifacts/utf-shard-summary.md
            artifacts/utf-shard-streak.json
            artifacts/utf-shard-streak.md
          if-no-files-found: error
          retention-days: 14
